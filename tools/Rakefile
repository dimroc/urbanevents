require_relative 'lib/tools'

namespace :es do
  def each_city_and_geojson_filename
    assignments = {
      jerseycities: "assets/neighborhoods/jersey-cities.geojson",
      nyc: "assets/neighborhoods/nyc/*.geojson",
      london: "assets/neighborhoods/london.geojson",
      paris: "assets/neighborhoods/paris.geojson",
      losangeles: "assets/neighborhoods/los-angeles-county.geojson",
      miami: "assets/neighborhoods/miami.geojson",
      austin: "assets/neighborhoods/austin.geojson",
    }

    assignments.each do |city, glob_path|
      Dir.glob(glob_path) do |filename|
        yield city, filename
      end
    end
  end

  def cities
    # Taken from cityservice/config/*
    # Yes, it's the long way to get cities, but at least it's DRY.
    cities = []
    each_city_and_geojson_filename do |city, glob_path|
      cities << city
    end
    cities.uniq.map(&:to_s)
  end

  def geojson_filenames
    filenames = []
    each_city_and_geojson_filename do |city, filename|
      filenames << filename
    end
    filenames
  end

  def backup_repository_name
    "urbanevents"
  end

  def es_alias
    "#{GO_ENV}-geoevents-write"
  end

  def repository(options={log: true})
    raise StandardError, "ELASTICSEARCH_URL must be set" unless ENV['ELASTICSEARCH_URL'].present?
    @repository ||= GeoeventRepository.new({url: ENV['ELASTICSEARCH_URL']}.merge(options))
  end

  def hood_repository(options={log: false})
    @hood_repository ||= HoodRepository.new({url: ENV['ELASTICSEARCH_URL']}.merge(options))
  end

  task :hello do
    puts "Watching the following cities: "
    puts cities
  end

  task :create_index do
    repository.create_index!
  end

  # Creates index, seed percolators and set ttl for another index.
  task :bootstrap_without_alias do
    repository.create_index!
    hood_repository(index: repository.index).update_mapping!
    seed_percolator_for(repository.index)
    Rake::Task["es:set_geoevent_ttl"].invoke
  end

  task :destroy_test_indices do
    repository.client.indices.delete index: 'test-geoevent*'
  end

  task :destroy_all => [:destroy_test_indices] do
    repository.client.indices.delete index: 'development-geoevent*'
  end

  task :bootstrap => [:create_index_and_alias, :seed_percolators, :set_geoevent_ttl]
  task :create_index_and_alias do
    repository.create_index!
    repository.client.indices.put_alias index: repository.index, name: es_alias
    hood_repository(index: es_alias).update_mapping!
  end

  task :set_geoevent_ttl do
    repository.client.indices.put_mapping({
      index: es_alias,
      type: :geoevent,
      body: {
        _ttl: { enabled: true, default: "120d" }
      }
    })
  end

  task :set_alias do
    old_index = ENV['OLD_INDEX']
    new_index = ENV['NEW_INDEX']

    if old_index.present?
      repository.client.indices.update_aliases body: {
        actions: [
          { remove: { index: old_index, alias: es_alias } },
          { add:    { index: new_index, alias: es_alias } }
        ]
      }
    else
      repository.client.indices.put_alias index: new_index, name: es_alias
    end
  end

  task :create_s3_repository do
    repository.client.snapshot.create_repository(repository: backup_repository_name,
      body: {
      "type": "s3",
      "settings": {
        "bucket": "#{GO_ENV}.urbanevents.elasticsearch",
        "region": "us-east",
        "access_key": ENV['AWS_ACCESS_KEY_ID'],
        "secret_key": ENV['AWS_SECRET_ACCESS_KEY']
      }
    })
  end

  task :create_fs_repository do
    repository.client.snapshot.create_repository(repository: backup_repository_name,
      body: {
      type: 'fs',
      settings: { location: '/tmp/elasticsearch-backups', compress: true  }
    })
  end

  task :snapshot do
    timestamp = Time.now.strftime("%Y%m%d-%H%M%S")
    repository.client.snapshot.create repository: backup_repository_name, snapshot: "cityservice-#{timestamp}"
  end

  task :restore do
    snapshot = ENV['SNAPSHOT']
    repository.client.snapshot.restore repository: backup_repository_name, snapshot: snapshot
  end

  task :health_last_hour do
    jj repository.builder.city_count_for_service_since(cities, 'twitter', 1.hour.ago).as_json
    jj repository.builder.city_count_for_service_since(cities, 'instagram', 1.hour.ago).as_json
  end

  task :report_health_last_hour do
    raise StandardError, "AWS ENV vars must be set" unless (ENV['AWS_REGION'] && ENV['AWS_SECRET_ACCESS_KEY'] && ENV['AWS_ACCESS_KEY_ID'])

    city_tweet_counts = repository.builder.city_count_for_service_since(cities, 'twitter', 1.hour.ago)
    city_tweet_counts.each do |key, count|
      puts "## Reporting #{key} with a tweet count of #{count} over the last hour"
      CloudMonitor.report_tweets(key, count)
    end

    city_instagram_counts = repository.builder.city_count_for_service_since(cities, 'instagram', 1.hour.ago)
    city_instagram_counts.each do |key, count|
      puts "## Reporting #{key} with a instagram count of #{count} over the last hour"
      CloudMonitor.report_instagrams(key, count)
    end
  end

  task :migrate_to_new_index do
    old_index = ENV['OLD_INDEX']
    raise ArgumentError, "OLD_INDEX must be set" unless old_index.present?

    repository(log: false).create_index!
    # We swap the index instead of having an alias point to multiple indices
    # since you cannot write to an alias pointing to multiple indices:
    # https://github.com/elastic/elasticsearch/issues/6240
    repository.client.indices.update_aliases body: {
      actions: [
        { remove: { index: old_index, alias: es_alias } },
        { add:    { index: repository.index, alias: es_alias } }
      ]
    }

    repository.copy_from old_index
  end

  task :seed_hoods do
    hood_repository(index: es_alias).create_index!

    each_city_and_geojson_filename do |city, filename|
      puts "Indexing neighborhoods from #{filename}"
      hood_repository.import_from filename
    end
  end

  def seed_percolator_for(index)
    each_city_and_geojson_filename do |city, filename|
      puts "Registering #{city}'s neighborhood percolator from #{filename}"
      repository(index: index).register_percolator(city, filename)
    end
  end

  task :seed_percolators do
    seed_percolator_for(es_alias)
  end

  task :write_clean_geojson_files do
    FileUtils.mkdir_p "tmp/clean_geojson"
    geojson_filenames.each do |filename|
      File.open("tmp/clean_geojson/#{File.basename(filename)}", "w+") do |f|
        puts "Writing #{f.path}"
        fc = FeatureCollection.new(filename)
        fc.clean_duplicate_coordinates!
        f.write JSON.pretty_generate(fc.as_json)
      end
    end
  end
end
